import type {
  UIMessage as ChatMessage,
  StreamTextOnFinishCallback,
  ToolSet
} from "ai";
import { convertToModelMessages } from "ai";
import { Agent, type AgentContext, type Connection, type WSMessage } from "./";
import type { IncomingMessage, OutgoingMessage } from "./ai-types";
import { MessageType } from "./ai-types";
import { needsMigration, migrateMessagesToUIFormat } from "./ai-migration";

const decoder = new TextDecoder();

/**
 * Extension of Agent with built-in chat capabilities
 * @template Env Environment type containing bindings
 */
export class AIChatAgent<Env = unknown, State = unknown> extends Agent<
  Env,
  State
> {
  /**
   * Map of message `id`s to `AbortController`s
   * useful to propagate request cancellation signals for any external calls made by the agent
   */
  private _chatMessageAbortControllers: Map<string, AbortController>;
  /** Array of chat messages for the current conversation */
  messages: ChatMessage[];
  constructor(ctx: AgentContext, env: Env) {
    super(ctx, env);
    this.sql`create table if not exists cf_ai_chat_agent_messages (
      id text primary key,
      message text not null,
      created_at datetime default current_timestamp
    )`;
    const rawMessages = this.sql`select * from cf_ai_chat_agent_messages` || [];

    this.messages = rawMessages.map((row) => {
      return JSON.parse(row.message as string);
    });

    // Check if any messages need migration and log notice
    if (needsMigration(this.messages)) {
      console.warn(
        "üîÑ [AIChatAgent] Detected messages in legacy format (role/content). " +
          "These will continue to work but consider migrating to the new message format " +
          "for better compatibility with AI SDK v5 features.\n" +
          "To migrate: import { migrateMessagesToUIFormat } from '@cloudflare/agents' and call " +
          "await this.persistMessages(migrateMessagesToUIFormat(this.messages))\n" +
          "See https://ai-sdk.dev/docs/migration-guides/migration-guide-5-0 for more info."
      );
    }

    this._chatMessageAbortControllers = new Map();
  }

  private _broadcastChatMessage(message: OutgoingMessage, exclude?: string[]) {
    this.broadcast(JSON.stringify(message), exclude);
  }

  override async onMessage(connection: Connection, message: WSMessage) {
    if (typeof message === "string") {
      let data: IncomingMessage;
      try {
        data = JSON.parse(message) as IncomingMessage;
      } catch (_error) {
        // silently ignore invalid messages for now
        // TODO: log errors with log levels
        return;
      }
      if (
        data.type === MessageType.CF_AGENT_USE_CHAT_REQUEST &&
        data.init.method === "POST"
      ) {
        const {
          // method,
          // keepalive,
          // headers,
          body // we're reading this
          //
          // // these might not exist?
          // dispatcher,
          // duplex
        } = data.init;
        const { messages } = JSON.parse(body as string);
        this._broadcastChatMessage(
          {
            messages,
            type: MessageType.CF_AGENT_CHAT_MESSAGES
          },
          [connection.id]
        );

        await this.persistMessages(messages, [connection.id]);

        this.observability?.emit(
          {
            displayMessage: "Chat message request",
            id: data.id,
            payload: {},
            timestamp: Date.now(),
            type: "message:request"
          },
          this.ctx
        );

        const chatMessageId = data.id;
        const abortSignal = this._getAbortSignal(chatMessageId);

        return this._tryCatchChat(async () => {
          const response = await this.onChatMessage(
            async (_finishResult) => {
              // each agent that extends AIChatAgent handles persistence in their own onChatMessage method
              this._removeAbortController(chatMessageId);

              this.observability?.emit(
                {
                  displayMessage: "Chat message response",
                  id: data.id,
                  payload: {},
                  timestamp: Date.now(),
                  type: "message:response"
                },
                this.ctx
              );
            },
            abortSignal ? { abortSignal } : undefined
          );

          if (response) {
            await this._reply(data.id, response);
          } else {
            // Log a warning for observability
            console.warn(
              `[AIChatAgent] onChatMessage returned no response for chatMessageId: ${chatMessageId}`
            );
            // Send a fallback message to the client
            this._broadcastChatMessage(
              {
                body: "No response was generated by the agent.",
                done: true,
                id: data.id,
                type: MessageType.CF_AGENT_USE_CHAT_RESPONSE
              },
              [connection.id]
            );
          }
        });
      }
      if (data.type === MessageType.CF_AGENT_CHAT_CLEAR) {
        this._destroyAbortControllers();
        this.sql`delete from cf_ai_chat_agent_messages`;
        this.messages = [];
        this._broadcastChatMessage(
          {
            type: MessageType.CF_AGENT_CHAT_CLEAR
          },
          [connection.id]
        );
      } else if (data.type === MessageType.CF_AGENT_CHAT_MESSAGES) {
        // replace the messages with the new ones
        await this.persistMessages(data.messages, [connection.id]);
      } else if (data.type === MessageType.CF_AGENT_CHAT_REQUEST_CANCEL) {
        // propagate an abort signal for the associated request
        this._cancelChatRequest(data.id);
      }
    }
  }

  override async onRequest(request: Request): Promise<Response> {
    return this._tryCatchChat(() => {
      const url = new URL(request.url);
      if (url.pathname.endsWith("/get-messages")) {
        const messages = (
          this.sql`select * from cf_ai_chat_agent_messages` || []
        ).map((row) => {
          return JSON.parse(row.message as string);
        });
        return Response.json(messages);
      }
      return super.onRequest(request);
    });
  }

  private async _tryCatchChat<T>(fn: () => T | Promise<T>) {
    try {
      return await fn();
    } catch (e) {
      throw this.onError(e);
    }
  }

  /**
   * Safely converts the current messages to the format expected by AI SDK model functions
   * Automatically handles corrupt message formats before conversion
   * @returns Messages converted to ModelMessage format for use with streamText, generateText, etc.
   */
  protected getModelMessages() {
    // First, clean any corrupt messages to ensure safe conversion
    const cleanMessages = migrateMessagesToUIFormat(this.messages);
    return convertToModelMessages(cleanMessages);
  }

  /**
   * Safe wrapper for convertToModelMessages with automatic corruption handling
   * @param messages - Messages to convert (will be cleaned if needed)
   * @returns Safely converted ModelMessages
   */
  protected convertToModelMessagesSafe(messages: ChatMessage[]) {
    try {
      const cleanMessages = migrateMessagesToUIFormat(messages);
      return convertToModelMessages(cleanMessages);
    } catch (error) {
      console.error("‚ùå Failed to convert messages safely:", error);
      // Return empty array as fallback to prevent crashes
      return [];
    }
  }

  /**
   * Handle incoming chat messages and generate a response
   * @param onFinish Callback to be called when the response is finished
   * @param options.signal A signal to pass to any child requests which can be used to cancel them
   * @returns Response to send to the client or undefined
   */
  async onChatMessage(
    // biome-ignore lint/correctness/noUnusedFunctionParameters: overridden later
    onFinish: StreamTextOnFinishCallback<ToolSet>,
    // biome-ignore lint/correctness/noUnusedFunctionParameters: overridden later
    options?: { abortSignal: AbortSignal | undefined }
  ): Promise<Response | undefined> {
    throw new Error(
      "recieved a chat message, override onChatMessage and return a Response to send to the client"
    );
  }

  /**
   * Save messages on the server side and trigger AI response
   * Now includes corruption detection to prevent future data issues
   * @param messages Chat messages to save
   */
  async saveMessages(messages: ChatMessage[]) {
    // Check for corruption and warn if found
    if (needsMigration(messages)) {
      console.warn(
        "‚ö†Ô∏è  saveMessages() detected corrupt message formats. Consider migrating data first."
      );
      // Auto-clean the messages to prevent corruption
      const cleanMessages = migrateMessagesToUIFormat(messages);
      await this.persistMessages(cleanMessages);
    } else {
      await this.persistMessages(messages);
    }

    const response = await this.onChatMessage(async (_finishResult) => {
      //  each agent that extends AIChatAgent handles persistence in their own onChatMessage method
    });
    if (response) {
      // Properly drain the response stream
      await this._drainStream(response.body);
    }
  }

  async persistMessages(
    messages: ChatMessage[],
    excludeBroadcastIds: string[] = []
  ) {
    this.sql`delete from cf_ai_chat_agent_messages`;
    for (const message of messages) {
      this.sql`insert into cf_ai_chat_agent_messages (id, message) values (${
        message.id
      },${JSON.stringify(message)})`;
    }
    this.messages = messages;
    this._broadcastChatMessage(
      {
        messages: messages,
        type: MessageType.CF_AGENT_CHAT_MESSAGES
      },
      excludeBroadcastIds
    );
  }

  private async _reply(id: string, response: Response) {
    // now take chunks out from dataStreamResponse and send them to the client
    return this._tryCatchChat(async () => {
      if (!response.body) return;

      const reader = response.body.getReader();
      let fullBody = "";
      let assistantText = "";

      try {
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;

          const body = decoder.decode(value);
          fullBody += body;

          // Extract text content from SSE chunks for storage
          // Parse each line that starts with "0:" which contains the text content
          const lines = body.split("\n");
          for (const line of lines) {
            if (line.startsWith("0:")) {
              try {
                const jsonPart = line.slice(2); // Remove "0:" prefix
                const parsed = JSON.parse(jsonPart);
                if (parsed.type === "text-delta" && parsed.textDelta) {
                  assistantText += parsed.textDelta;
                }
              } catch (e) {
                // Ignore parsing errors for malformed chunks
              }
            }
          }

          this._broadcastChatMessage({
            body,
            done: false,
            id,
            type: MessageType.CF_AGENT_USE_CHAT_RESPONSE
          });
        }
      } finally {
        reader.releaseLock();
      }

      this._broadcastChatMessage({
        body: "",
        done: true,
        id,
        type: MessageType.CF_AGENT_USE_CHAT_RESPONSE
      });

      await this.persistMessages([
        ...this.messages,
        {
          id: crypto.randomUUID(),
          role: "assistant",
          parts: [{ type: "text", text: assistantText || fullBody }] // Fallback to fullBody if parsing fails
        }
      ]);
    });
  }

  /**
   * For the given message id, look up its associated AbortController
   * If the AbortController does not exist, create and store one in memory
   *
   * returns the AbortSignal associated with the AbortController
   */
  private _getAbortSignal(id: string): AbortSignal | undefined {
    // Defensive check, since we're coercing message types at the moment
    if (typeof id !== "string") {
      return undefined;
    }

    if (!this._chatMessageAbortControllers.has(id)) {
      this._chatMessageAbortControllers.set(id, new AbortController());
    }

    return this._chatMessageAbortControllers.get(id)?.signal;
  }

  /**
   * Remove an abort controller from the cache of pending message responses
   */
  private _removeAbortController(id: string) {
    this._chatMessageAbortControllers.delete(id);
  }

  /**
   * Propagate an abort signal for any requests associated with the given message id
   */
  private _cancelChatRequest(id: string) {
    if (this._chatMessageAbortControllers.has(id)) {
      const abortController = this._chatMessageAbortControllers.get(id);
      abortController?.abort();
    }
  }

  /**
   * Abort all pending requests and clear the cache of AbortControllers
   */
  private _destroyAbortControllers() {
    for (const controller of this._chatMessageAbortControllers.values()) {
      controller?.abort();
    }
    this._chatMessageAbortControllers.clear();
  }

  /**
   * Properly drains and cancels a ReadableStream
   */
  private async _drainStream(stream: ReadableStream<Uint8Array> | null) {
    if (!stream) return;

    const reader = stream.getReader();
    try {
      // Read all chunks to drain the stream
      // eslint-disable-next-line no-constant-condition
      while (true) {
        const { done } = await reader.read();
        if (done) break;
      }
    } finally {
      // Always release the reader lock
      reader.releaseLock();
    }
  }

  /**
   * When the DO is destroyed, cancel all pending requests
   */
  async destroy() {
    this._destroyAbortControllers();
    await super.destroy();
  }
}
